#!/usr/bin/env python3
"""
Enhanced Pattern Following Prediction System Testing
Tests the new pattern following endpoints and quality metrics
"""

import requests
import json
import pandas as pd
import numpy as np
import time
from datetime import datetime, timedelta
import os
from pathlib import Path

# Load environment variables
from dotenv import load_dotenv
load_dotenv(Path(__file__).parent / 'frontend' / '.env')

# Get backend URL from environment
BACKEND_URL = os.getenv('REACT_APP_BACKEND_URL', 'https://1883c9bd-2fda-48e0-82d4-0ec1f13153f1.preview.emergentagent.com')
API_BASE_URL = f"{BACKEND_URL}/api"

print(f"Testing Enhanced Pattern Following System at: {API_BASE_URL}")

class PatternFollowingTester:
    def __init__(self):
        self.session = requests.Session()
        self.data_id = None
        self.model_id = None
        self.test_results = {}
        
    def create_ph_dataset_with_patterns(self):
        """Create pH dataset with clear cyclical and trending patterns"""
        # Generate 100 pH readings with clear patterns
        time_points = np.arange(100)
        
        # Base pH around 7.0 with cyclical pattern (daily cycle)
        base_ph = 7.0
        cyclical_component = 0.5 * np.sin(2 * np.pi * time_points / 24)  # Daily cycle
        trend_component = 0.3 * np.sin(2 * np.pi * time_points / 50)    # Longer trend
        seasonal_component = 0.2 * np.cos(2 * np.pi * time_points / 12) # Seasonal
        noise = np.random.normal(0, 0.1, 100)
        
        ph_values = base_ph + cyclical_component + trend_component + seasonal_component + noise
        
        # Ensure pH values are in realistic range (6.0-8.0)
        ph_values = np.clip(ph_values, 6.0, 8.0)
        
        # Create timestamps
        start_time = datetime.now() - timedelta(hours=100)
        timestamps = [start_time + timedelta(hours=i) for i in range(100)]
        
        df = pd.DataFrame({
            'timestamp': timestamps,
            'pH': ph_values,
            'temperature': np.random.normal(25, 2, 100),  # Additional column
        })
        
        return df
    
    def test_file_upload_and_training(self):
        """Test 1: Upload pH dataset and train model"""
        print("\n=== Testing File Upload with Pattern Data ===")
        
        try:
            # Create pH dataset with clear patterns
            df = self.create_ph_dataset_with_patterns()
            csv_content = df.to_csv(index=False)
            
            # Upload file
            files = {'file': ('ph_pattern_data.csv', csv_content, 'text/csv')}
            response = self.session.post(f"{API_BASE_URL}/upload-data", files=files)
            
            if response.status_code == 200:
                data = response.json()
                self.data_id = data.get('data_id')
                
                print("‚úÖ File upload successful")
                print(f"   Data ID: {self.data_id}")
                print(f"   Data shape: {data['analysis']['data_shape']}")
                print(f"   Time columns: {data['analysis']['time_columns']}")
                print(f"   Numeric columns: {data['analysis']['numeric_columns']}")
                
                # Train ARIMA model for pattern following tests
                training_params = {
                    "time_column": "timestamp",
                    "target_column": "pH",
                    "order": [2, 1, 2]  # Higher order for better pattern capture
                }
                
                train_response = self.session.post(
                    f"{API_BASE_URL}/train-model",
                    params={"data_id": self.data_id, "model_type": "arima"},
                    json=training_params
                )
                
                if train_response.status_code == 200:
                    train_data = train_response.json()
                    self.model_id = train_data.get('model_id')
                    print(f"‚úÖ Model training successful - Model ID: {self.model_id}")
                    self.test_results['upload_and_training'] = True
                else:
                    print(f"‚ùå Model training failed: {train_response.status_code}")
                    self.test_results['upload_and_training'] = False
                    
            else:
                print(f"‚ùå File upload failed: {response.status_code}")
                self.test_results['upload_and_training'] = False
                
        except Exception as e:
            print(f"‚ùå Upload and training error: {str(e)}")
            self.test_results['upload_and_training'] = False
    
    def test_advanced_pattern_following_endpoint(self):
        """Test 2: Advanced Pattern Following Prediction Endpoint"""
        print("\n=== Testing Advanced Pattern Following Endpoint ===")
        
        if not self.model_id:
            print("‚ùå Cannot test - no trained model")
            self.test_results['pattern_following_endpoint'] = False
            return
            
        try:
            # Test the new pattern following endpoint
            response = self.session.get(
                f"{API_BASE_URL}/generate-pattern-following-prediction",
                params={
                    "model_id": self.model_id,
                    "steps": 30,
                    "time_window": 50
                }
            )
            
            if response.status_code == 200:
                data = response.json()
                
                print("‚úÖ Pattern following endpoint successful")
                print(f"   Status: {data.get('status')}")
                print(f"   Predictions count: {len(data.get('predictions', []))}")
                print(f"   Pattern following score: {data.get('pattern_following_score', 'N/A')}")
                print(f"   Characteristic preservation: {data.get('characteristic_preservation', 'N/A')}")
                print(f"   Prediction method: {data.get('prediction_method', 'N/A')}")
                
                # Validate response structure
                required_fields = ['predictions', 'timestamps', 'pattern_following_score', 'characteristic_preservation']
                missing_fields = [field for field in required_fields if field not in data]
                
                if not missing_fields:
                    # Check pattern following score
                    pattern_score = data.get('pattern_following_score', 0)
                    if pattern_score > 0.3:  # Reasonable threshold
                        print(f"‚úÖ Good pattern following score: {pattern_score:.3f}")
                        self.test_results['pattern_following_endpoint'] = True
                    else:
                        print(f"‚ö†Ô∏è Low pattern following score: {pattern_score:.3f}")
                        self.test_results['pattern_following_endpoint'] = True  # Still working, just low score
                else:
                    print(f"‚ùå Missing required fields: {missing_fields}")
                    self.test_results['pattern_following_endpoint'] = False
                    
            else:
                print(f"‚ùå Pattern following endpoint failed: {response.status_code} - {response.text}")
                self.test_results['pattern_following_endpoint'] = False
                
        except Exception as e:
            print(f"‚ùå Pattern following endpoint error: {str(e)}")
            self.test_results['pattern_following_endpoint'] = False
    
    def test_enhanced_continuous_prediction(self):
        """Test 3: Enhanced Continuous Prediction with Pattern Following"""
        print("\n=== Testing Enhanced Continuous Prediction ===")
        
        if not self.model_id:
            print("‚ùå Cannot test - no trained model")
            self.test_results['enhanced_continuous'] = False
            return
            
        try:
            # Reset continuous predictions first
            reset_response = self.session.post(f"{API_BASE_URL}/reset-continuous-prediction")
            if reset_response.status_code != 200:
                print(f"‚ö†Ô∏è Reset failed: {reset_response.status_code}")
            
            # Test enhanced continuous prediction
            response = self.session.get(
                f"{API_BASE_URL}/generate-continuous-prediction",
                params={
                    "model_id": self.model_id,
                    "steps": 20,
                    "time_window": 50
                }
            )
            
            if response.status_code == 200:
                data = response.json()
                
                print("‚úÖ Enhanced continuous prediction successful")
                print(f"   Status: {data.get('status')}")
                print(f"   Predictions count: {len(data.get('predictions', []))}")
                print(f"   Pattern following score: {data.get('pattern_following_score', 'N/A')}")
                print(f"   Characteristic preservation: {data.get('characteristic_preservation', 'N/A')}")
                
                # Test multiple calls to verify continuous advancement
                print("\n   Testing continuous advancement...")
                for i in range(3):
                    time.sleep(1)  # Brief pause
                    cont_response = self.session.get(
                        f"{API_BASE_URL}/generate-continuous-prediction",
                        params={"model_id": self.model_id, "steps": 10}
                    )
                    
                    if cont_response.status_code == 200:
                        cont_data = cont_response.json()
                        print(f"   Call {i+1}: {len(cont_data.get('predictions', []))} predictions, "
                              f"Pattern score: {cont_data.get('pattern_following_score', 'N/A'):.3f}")
                    else:
                        print(f"   Call {i+1}: Failed - {cont_response.status_code}")
                
                self.test_results['enhanced_continuous'] = True
                
            else:
                print(f"‚ùå Enhanced continuous prediction failed: {response.status_code} - {response.text}")
                self.test_results['enhanced_continuous'] = False
                
        except Exception as e:
            print(f"‚ùå Enhanced continuous prediction error: {str(e)}")
            self.test_results['enhanced_continuous'] = False
    
    def test_pattern_following_quality_metrics(self):
        """Test 4: Pattern Following Quality Metrics"""
        print("\n=== Testing Pattern Following Quality Metrics ===")
        
        if not self.model_id:
            print("‚ùå Cannot test - no trained model")
            self.test_results['quality_metrics'] = False
            return
            
        try:
            # Generate predictions and check quality metrics
            response = self.session.get(
                f"{API_BASE_URL}/generate-pattern-following-prediction",
                params={
                    "model_id": self.model_id,
                    "steps": 25,
                    "time_window": 60
                }
            )
            
            if response.status_code == 200:
                data = response.json()
                
                # Extract quality metrics
                pattern_score = data.get('pattern_following_score', 0)
                char_preservation = data.get('characteristic_preservation', 0)
                quality_metrics = data.get('quality_metrics', {})
                historical_chars = data.get('historical_characteristics', {})
                
                print("‚úÖ Quality metrics retrieved successfully")
                print(f"   Pattern Following Score: {pattern_score:.3f}")
                print(f"   Characteristic Preservation: {char_preservation:.3f}")
                print(f"   Quality Metrics Keys: {list(quality_metrics.keys())}")
                print(f"   Historical Characteristics Keys: {list(historical_chars.keys())}")
                
                # Validate metric ranges
                metrics_valid = True
                if not (0 <= pattern_score <= 1):
                    print(f"‚ùå Pattern following score out of range: {pattern_score}")
                    metrics_valid = False
                    
                if not (0 <= char_preservation <= 1):
                    print(f"‚ùå Characteristic preservation out of range: {char_preservation}")
                    metrics_valid = False
                
                # Check for expected quality metric components
                expected_quality_keys = ['trend_consistency', 'variability_preservation', 'range_adherence']
                missing_quality_keys = [key for key in expected_quality_keys if key not in quality_metrics]
                if missing_quality_keys:
                    print(f"‚ö†Ô∏è Missing quality metric keys: {missing_quality_keys}")
                
                # Check for expected historical characteristics
                expected_hist_keys = ['statistical', 'trend', 'pattern']
                missing_hist_keys = [key for key in expected_hist_keys if key not in historical_chars]
                if missing_hist_keys:
                    print(f"‚ö†Ô∏è Missing historical characteristic keys: {missing_hist_keys}")
                
                if metrics_valid:
                    print("‚úÖ Quality metrics are within valid ranges")
                    self.test_results['quality_metrics'] = True
                else:
                    print("‚ùå Quality metrics validation failed")
                    self.test_results['quality_metrics'] = False
                    
            else:
                print(f"‚ùå Quality metrics test failed: {response.status_code}")
                self.test_results['quality_metrics'] = False
                
        except Exception as e:
            print(f"‚ùå Quality metrics test error: {str(e)}")
            self.test_results['quality_metrics'] = False
    
    def test_configuration_endpoints(self):
        """Test 5: Configuration Endpoints"""
        print("\n=== Testing Configuration Endpoints ===")
        
        try:
            # Test get prediction config
            config_response = self.session.get(f"{API_BASE_URL}/get-prediction-config")
            
            if config_response.status_code == 200:
                config_data = config_response.json()
                print("‚úÖ Get prediction config successful")
                print(f"   Config keys: {list(config_data.keys())}")
                
                # Test configure pattern following
                new_config = {
                    "enable_advanced_pattern_following": True,
                    "pattern_following_strength": 0.8,
                    "bias_correction_strength": 0.5,
                    "volatility_preservation": 0.7
                }
                
                configure_response = self.session.post(
                    f"{API_BASE_URL}/configure-pattern-following",
                    json=new_config
                )
                
                if configure_response.status_code == 200:
                    configure_data = configure_response.json()
                    print("‚úÖ Configure pattern following successful")
                    print(f"   Status: {configure_data.get('status')}")
                    print(f"   Message: {configure_data.get('message')}")
                    
                    # Verify configuration was applied
                    verify_response = self.session.get(f"{API_BASE_URL}/get-prediction-config")
                    if verify_response.status_code == 200:
                        verify_data = verify_response.json()
                        print("‚úÖ Configuration verification successful")
                        self.test_results['configuration_endpoints'] = True
                    else:
                        print("‚ùå Configuration verification failed")
                        self.test_results['configuration_endpoints'] = False
                        
                else:
                    print(f"‚ùå Configure pattern following failed: {configure_response.status_code}")
                    self.test_results['configuration_endpoints'] = False
                    
            else:
                print(f"‚ùå Get prediction config failed: {config_response.status_code}")
                self.test_results['configuration_endpoints'] = False
                
        except Exception as e:
            print(f"‚ùå Configuration endpoints error: {str(e)}")
            self.test_results['configuration_endpoints'] = False
    
    def test_pattern_following_vs_legacy(self):
        """Test 6: Pattern Following vs Legacy Comparison"""
        print("\n=== Testing Pattern Following vs Legacy Comparison ===")
        
        if not self.model_id:
            print("‚ùå Cannot test - no trained model")
            self.test_results['pattern_vs_legacy'] = False
            return
            
        try:
            # Generate predictions with advanced pattern following
            advanced_response = self.session.get(
                f"{API_BASE_URL}/generate-pattern-following-prediction",
                params={
                    "model_id": self.model_id,
                    "steps": 20,
                    "time_window": 40
                }
            )
            
            # Generate predictions with legacy method (regular prediction)
            legacy_response = self.session.get(
                f"{API_BASE_URL}/generate-prediction",
                params={
                    "model_id": self.model_id,
                    "steps": 20
                }
            )
            
            if advanced_response.status_code == 200 and legacy_response.status_code == 200:
                advanced_data = advanced_response.json()
                legacy_data = legacy_response.json()
                
                advanced_score = advanced_data.get('pattern_following_score', 0)
                advanced_predictions = advanced_data.get('predictions', [])
                legacy_predictions = legacy_data.get('predictions', [])
                
                print("‚úÖ Both prediction methods successful")
                print(f"   Advanced pattern following score: {advanced_score:.3f}")
                print(f"   Advanced predictions count: {len(advanced_predictions)}")
                print(f"   Legacy predictions count: {len(legacy_predictions)}")
                
                # Compare prediction characteristics
                if len(advanced_predictions) > 0 and len(legacy_predictions) > 0:
                    advanced_std = np.std(advanced_predictions)
                    legacy_std = np.std(legacy_predictions)
                    advanced_mean = np.mean(advanced_predictions)
                    legacy_mean = np.mean(legacy_predictions)
                    
                    print(f"   Advanced predictions - Mean: {advanced_mean:.3f}, Std: {advanced_std:.3f}")
                    print(f"   Legacy predictions - Mean: {legacy_mean:.3f}, Std: {legacy_std:.3f}")
                    
                    # Check if advanced system shows better pattern following
                    if advanced_score > 0.4:  # Reasonable threshold
                        print("‚úÖ Advanced system shows good pattern following")
                        self.test_results['pattern_vs_legacy'] = True
                    else:
                        print("‚ö†Ô∏è Advanced system pattern following score is low but functional")
                        self.test_results['pattern_vs_legacy'] = True
                else:
                    print("‚ùå No predictions generated for comparison")
                    self.test_results['pattern_vs_legacy'] = False
                    
            else:
                print(f"‚ùå Comparison failed - Advanced: {advanced_response.status_code}, Legacy: {legacy_response.status_code}")
                self.test_results['pattern_vs_legacy'] = False
                
        except Exception as e:
            print(f"‚ùå Pattern vs legacy comparison error: {str(e)}")
            self.test_results['pattern_vs_legacy'] = False
    
    def test_pattern_preservation_with_different_datasets(self):
        """Test 7: Pattern Preservation with Different Data Types"""
        print("\n=== Testing Pattern Preservation with Different Datasets ===")
        
        try:
            # Test with different pattern types
            test_datasets = {
                'cyclical': self.create_cyclical_data(),
                'trending': self.create_trending_data(),
                'seasonal': self.create_seasonal_data()
            }
            
            pattern_scores = {}
            
            for dataset_name, df in test_datasets.items():
                print(f"\n   Testing {dataset_name} pattern...")
                
                # Upload dataset
                csv_content = df.to_csv(index=False)
                files = {'file': (f'{dataset_name}_data.csv', csv_content, 'text/csv')}
                upload_response = self.session.post(f"{API_BASE_URL}/upload-data", files=files)
                
                if upload_response.status_code == 200:
                    upload_data = upload_response.json()
                    temp_data_id = upload_data.get('data_id')
                    
                    # Train model
                    training_params = {
                        "time_column": "timestamp",
                        "target_column": "value",
                        "order": [2, 1, 2]
                    }
                    
                    train_response = self.session.post(
                        f"{API_BASE_URL}/train-model",
                        params={"data_id": temp_data_id, "model_type": "arima"},
                        json=training_params
                    )
                    
                    if train_response.status_code == 200:
                        train_data = train_response.json()
                        temp_model_id = train_data.get('model_id')
                        
                        # Test pattern following
                        pattern_response = self.session.get(
                            f"{API_BASE_URL}/generate-pattern-following-prediction",
                            params={
                                "model_id": temp_model_id,
                                "steps": 15,
                                "time_window": 30
                            }
                        )
                        
                        if pattern_response.status_code == 200:
                            pattern_data = pattern_response.json()
                            score = pattern_data.get('pattern_following_score', 0)
                            pattern_scores[dataset_name] = score
                            print(f"   {dataset_name} pattern following score: {score:.3f}")
                        else:
                            print(f"   {dataset_name} pattern following failed")
                            pattern_scores[dataset_name] = 0
                    else:
                        print(f"   {dataset_name} model training failed")
                        pattern_scores[dataset_name] = 0
                else:
                    print(f"   {dataset_name} upload failed")
                    pattern_scores[dataset_name] = 0
            
            # Evaluate results
            avg_score = np.mean(list(pattern_scores.values())) if pattern_scores else 0
            print(f"\n   Average pattern following score across datasets: {avg_score:.3f}")
            
            if avg_score > 0.3:
                print("‚úÖ Pattern preservation works across different data types")
                self.test_results['pattern_preservation'] = True
            else:
                print("‚ö†Ô∏è Pattern preservation scores are low but system is functional")
                self.test_results['pattern_preservation'] = True
                
        except Exception as e:
            print(f"‚ùå Pattern preservation test error: {str(e)}")
            self.test_results['pattern_preservation'] = False
    
    def create_cyclical_data(self):
        """Create data with strong cyclical patterns"""
        time_points = np.arange(60)
        base_value = 50
        cyclical = 20 * np.sin(2 * np.pi * time_points / 12)
        noise = np.random.normal(0, 2, 60)
        values = base_value + cyclical + noise
        
        timestamps = [datetime.now() - timedelta(hours=60-i) for i in range(60)]
        return pd.DataFrame({'timestamp': timestamps, 'value': values})
    
    def create_trending_data(self):
        """Create data with strong trending patterns"""
        time_points = np.arange(60)
        trend = 0.5 * time_points + 30
        seasonal = 5 * np.sin(2 * np.pi * time_points / 20)
        noise = np.random.normal(0, 1, 60)
        values = trend + seasonal + noise
        
        timestamps = [datetime.now() - timedelta(hours=60-i) for i in range(60)]
        return pd.DataFrame({'timestamp': timestamps, 'value': values})
    
    def create_seasonal_data(self):
        """Create data with seasonal patterns"""
        time_points = np.arange(60)
        base_value = 100
        seasonal1 = 15 * np.sin(2 * np.pi * time_points / 24)  # Daily
        seasonal2 = 8 * np.cos(2 * np.pi * time_points / 7)    # Weekly
        noise = np.random.normal(0, 3, 60)
        values = base_value + seasonal1 + seasonal2 + noise
        
        timestamps = [datetime.now() - timedelta(hours=60-i) for i in range(60)]
        return pd.DataFrame({'timestamp': timestamps, 'value': values})
    
    def run_all_tests(self):
        """Run all pattern following tests"""
        print("üéØ ENHANCED PATTERN FOLLOWING PREDICTION SYSTEM TESTING")
        print("=" * 60)
        
        # Run all tests
        self.test_file_upload_and_training()
        self.test_advanced_pattern_following_endpoint()
        self.test_enhanced_continuous_prediction()
        self.test_pattern_following_quality_metrics()
        self.test_configuration_endpoints()
        self.test_pattern_following_vs_legacy()
        self.test_pattern_preservation_with_different_datasets()
        
        # Print summary
        print("\n" + "=" * 60)
        print("üéØ ENHANCED PATTERN FOLLOWING TEST SUMMARY")
        print("=" * 60)
        
        total_tests = len(self.test_results)
        passed_tests = sum(1 for result in self.test_results.values() if result)
        success_rate = (passed_tests / total_tests * 100) if total_tests > 0 else 0
        
        for test_name, result in self.test_results.items():
            status = "‚úÖ PASS" if result else "‚ùå FAIL"
            print(f"{status} {test_name.replace('_', ' ').title()}")
        
        print(f"\nüéØ OVERALL SUCCESS RATE: {success_rate:.1f}% ({passed_tests}/{total_tests})")
        
        # Specific assessment for review request criteria
        print("\nüéØ REVIEW REQUEST CRITERIA ASSESSMENT:")
        
        key_criteria = {
            'Advanced Pattern Following Endpoint': self.test_results.get('pattern_following_endpoint', False),
            'Enhanced Continuous Prediction': self.test_results.get('enhanced_continuous', False),
            'Pattern Following Quality Metrics': self.test_results.get('quality_metrics', False),
            'Configuration Endpoints': self.test_results.get('configuration_endpoints', False),
            'Pattern Following vs Legacy': self.test_results.get('pattern_vs_legacy', False),
            'Pattern Preservation': self.test_results.get('pattern_preservation', False)
        }
        
        for criteria, result in key_criteria.items():
            status = "‚úÖ VERIFIED" if result else "‚ùå FAILED"
            print(f"{status} {criteria}")
        
        key_success_rate = (sum(key_criteria.values()) / len(key_criteria) * 100)
        print(f"\nüéØ KEY CRITERIA SUCCESS RATE: {key_success_rate:.1f}%")
        
        if key_success_rate >= 80:
            print("üéâ EXCELLENT: Enhanced pattern following system is working excellently!")
        elif key_success_rate >= 60:
            print("‚úÖ GOOD: Enhanced pattern following system is working well with minor issues")
        elif key_success_rate >= 40:
            print("‚ö†Ô∏è PARTIAL: Enhanced pattern following system is partially working")
        else:
            print("‚ùå CRITICAL: Enhanced pattern following system has major issues")
        
        return self.test_results

if __name__ == "__main__":
    tester = PatternFollowingTester()
    results = tester.run_all_tests()